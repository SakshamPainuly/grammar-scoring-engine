# üéôÔ∏è Grammar Scoring Engine  
### **SHL Research Intern ‚Äì Technical Assessment Submission**

A lightweight speech-to-score system that analyzes spoken English responses and outputs:

- **Transcript**
- **Grammar score**
- **Fluency score**
- **Overall communication score**
- **Diagnostics & feedback**

The system includes a **REST API (FastAPI)** and a **demo UI (Gradio)**.

---

## ‚úÖ Features (Quick Summary)

- **ASR:** Faster-Whisper (tiny, CPU-optimized)  
- **Grammar Scoring:** Heuristics (capitalization, punctuation, repeated words, structure)  
- **Fluency:** Words/minute + filler penalty  
- **Aggregation:** Weighted scoring  
- **UI:** Gradio interface for audio scoring  
- **API:** FastAPI with `/score` endpoint  

---

## ‚úÖ Tech Stack

- Python  
- FastAPI  
- Gradio  
- Faster-Whisper (ctranslate2 backend)  
- ffmpeg (optional)  
- Uvicorn, Requests  

---

## ‚úÖ How It Works (Pipeline)

```
Audio
 ‚Üí Preprocessing
 ‚Üí ASR (Faster-Whisper)
 ‚Üí Grammar Heuristics
 ‚Üí Fluency Scoring
 ‚Üí Weighted Aggregation
 ‚Üí JSON Output
```

---

## ‚úÖ API Usage

### **POST /score**

Upload `.wav` or `.mp3`:

```
curl -X POST http://127.0.0.1:8000/score \
  -F "audio=@sample.wav"
```

Example output:

```
{
  "overall": 90.3,
  "grammar": 90,
  "fluency": 94.4,
  "transcript": "The stale smell of old beer lingers...",
  "diagnostics": ["Contains double spaces."]
}
```

---

## ‚úÖ Run Locally

Install dependencies:

```
pip install -r requirements.txt
```

Start backend:

```
uvicorn api.main:app --reload
```

Start UI:

```
python demo/app.py
```

Backend Docs ‚Üí http://127.0.0.1:8000/docs  
UI ‚Üí http://127.0.0.1:7860  

---

## ‚úÖ Project Structure (Minimal)

```
api/          ‚Üê FastAPI backend
src/          ‚Üê ASR, grammar, fluency, scoring modules
demo/         ‚Üê Gradio UI
models/       ‚Üê Scoring config
```

---

## ‚úÖ Scoring Logic (Brief)

- Grammar: heuristic rule violations  
- Fluency: WPM + filler detection  
- Pronunciation: placeholder constant  
- Final score = weighted sum (`scoring_config.json`)  

---

## ‚úÖ Why This Approach (For SHL Reviewers)

- Lightweight and deployable  
- Cross-platform (Windows/Linux/Cloud)  
- Fast inference (CPU-only)  
- No heavy dependencies like Java  
- Research-friendly modular design  
- Complete pipeline: **ASR ‚Üí NLP ‚Üí Scoring ‚Üí API ‚Üí UI**  

---

## ‚úÖ Future Enhancements

- Transformer-based grammar scoring  
- Pronunciation scoring via CTC alignment  
- Improved VAD (Silero/WebRTC)  
- Multi-speaker support  
